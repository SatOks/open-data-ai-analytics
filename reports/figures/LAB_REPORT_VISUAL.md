# üìä –ó–≤—ñ—Ç –∑ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ—ó —Ä–æ–±–æ—Ç–∏: Open Data AI Analytics

**–°—Ç—É–¥–µ–Ω—Ç:** –ì–∞—Ä–≥–∞–π –Æ—Ä—ñ–π
**–ì—Ä—É–ø–∞:** –®–Ü-33 
**–î–∞—Ç–∞:** 23 –ª—é—Ç–æ–≥–æ 2026  
**–ü—Ä–æ—î–∫—Ç:** –ê–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö WHO Life Expectancy –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º Git —Ç–∞ Machine Learning

---

## üìå –ó–º—ñ—Å—Ç

1. [–û–ø–∏—Å –ø—Ä–æ—î–∫—Ç—É](#–æ–ø–∏—Å-–ø—Ä–æ—î–∫—Ç—É)
2. [–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ—é](#—Å—Ç—Ä—É–∫—Ç—É—Ä–∞-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ—é)
3. [Git Workflow](#git-workflow)
4. [–ê–Ω–∞–ª—ñ–∑ —è–∫–æ—Å—Ç—ñ –¥–∞–Ω–∏—Ö](#–∞–Ω–∞–ª—ñ–∑-—è–∫–æ—Å—Ç—ñ-–¥–∞–Ω–∏—Ö)
5. [–î–æ—Å–ª—ñ–¥–Ω–∏—Ü—å–∫—ñ –≥—ñ–ø–æ—Ç–µ–∑–∏](#–¥–æ—Å–ª—ñ–¥–Ω–∏—Ü—å–∫—ñ-–≥—ñ–ø–æ—Ç–µ–∑–∏)
6. [Machine Learning –º–æ–¥–µ–ª—ñ](#machine-learning-–º–æ–¥–µ–ª—ñ)
7. [–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤](#–≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤)
8. [–í–∏—Å–Ω–æ–≤–∫–∏](#–≤–∏—Å–Ω–æ–≤–∫–∏)

---

## üéØ –û–ø–∏—Å –ø—Ä–æ—î–∫—Ç—É

### –ú–µ—Ç–∞ —Ä–æ–±–æ—Ç–∏
–†–æ–∑—Ä–æ–±–∏—Ç–∏ –ø–æ–≤–Ω–æ—Ü—ñ–Ω–Ω–∏–π data science –ø—Ä–æ—î–∫—Ç –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º:
- ‚úÖ Git version control –∑ feature branches
- ‚úÖ –ú–æ–¥—É–ª—å–Ω–æ—ó –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏ Python
- ‚úÖ –ê–Ω–∞–ª—ñ–∑—É –¥–∞–Ω–∏—Ö —Ç–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —è–∫–æ—Å—Ç—ñ
- ‚úÖ Machine Learning –º–æ–¥–µ–ª—é–≤–∞–Ω–Ω—è
- ‚úÖ –ü—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ—ó –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤

### –î–∞—Ç–∞—Å–µ—Ç
**–î–∂–µ—Ä–µ–ª–æ:** [Life Expectancy (WHO)](https://www.kaggle.com/datasets/kumarajarshi/life-expectancy-who/data)

**–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**
- üìÖ –ü–µ—Ä—ñ–æ–¥: 2000-2015 —Ä–æ–∫–∏
- üåç –ö—Ä–∞—ó–Ω–∏: 193
- üìä –ó–º—ñ–Ω–Ω—ñ: 22 (–µ–∫–æ–Ω–æ–º—ñ—á–Ω—ñ, –º–µ–¥–∏—á–Ω—ñ, —Å–æ—Ü—ñ–∞–ª—å–Ω—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏)
- üéØ –¶—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞: Life expectancy (–æ—á—ñ–∫—É–≤–∞–Ω–∞ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –∂–∏—Ç—Ç—è)

### –û—Å–Ω–æ–≤–Ω—ñ –ø–∏—Ç–∞–Ω–Ω—è –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è
1. –Ø–∫ –µ–∫–æ–Ω–æ–º—ñ—á–Ω—ñ —Ñ–∞–∫—Ç–æ—Ä–∏ (GDP) –≤–ø–ª–∏–≤–∞—é—Ç—å –Ω–∞ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –∂–∏—Ç—Ç—è?
2. –ß–∏ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∞ –º–∞—Å–æ–≤–∞ —ñ–º—É–Ω—ñ–∑–∞—Ü—ñ—è –¥–ª—è –∑–Ω–∏–∂–µ–Ω–Ω—è –¥–∏—Ç—è—á–æ—ó —Å–º–µ—Ä—Ç–Ω–æ—Å—Ç—ñ?
3. –ß–∏ –º–æ–∂–Ω–∞ —Ç–æ—á–Ω–æ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞—Ç–∏ Life Expectancy –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é ML?

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ—é

```
open-data-ai-analytics/
‚îÇ
‚îú‚îÄ‚îÄ üìÇ data/                        # –î–∞–Ω—ñ (–Ω–µ –≤ Git)
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Life Expectancy Data.csv
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ üìÇ notebooks/                   # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_loading.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_data_quality_analysis.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_data_research.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 04_visualization.ipynb
‚îÇ
‚îú‚îÄ‚îÄ üìÇ src/                         # Python –º–æ–¥—É–ª—ñ
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data_load.py               # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
‚îÇ   ‚îú‚îÄ‚îÄ data_quality_analysis.py   # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —è–∫–æ—Å—Ç—ñ
‚îÇ   ‚îú‚îÄ‚îÄ data_research.py           # ML –º–æ–¥–µ–ª—ñ
‚îÇ   ‚îî‚îÄ‚îÄ visualization.py           # –ì—Ä–∞—Ñ—ñ–∫–∏
‚îÇ
‚îú‚îÄ‚îÄ üìÇ reports/                     # –ó–≤—ñ—Ç–∏ —Ç–∞ –≥—Ä–∞—Ñ—ñ–∫–∏
‚îÇ   ‚îî‚îÄ‚îÄ figures/
‚îÇ       ‚îú‚îÄ‚îÄ correlation_matrix.png
‚îÇ       ‚îú‚îÄ‚îÄ distribution_Life_expectancy_.png
‚îÇ       ‚îî‚îÄ‚îÄ missing_values.png
‚îÇ
‚îú‚îÄ‚îÄ üìÑ .gitignore                   # –í–∏–∫–ª—é—á–µ–Ω–Ω—è –∑ Git
‚îú‚îÄ‚îÄ üìÑ README.md                    # –û–ø–∏—Å –ø—Ä–æ—î–∫—Ç—É
‚îú‚îÄ‚îÄ üìÑ requirements.txt             # –ó–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ
‚îú‚îÄ‚îÄ üìÑ CHANGELOG.md                 # –Ü—Å—Ç–æ—Ä—ñ—è –≤–µ—Ä—Å—ñ–π
‚îú‚îÄ‚îÄ üìÑ REPORT.md                    # –¢–µ—Ö–Ω—ñ—á–Ω–∏–π –∑–≤—ñ—Ç
‚îî‚îÄ‚îÄ üìÑ HINT.md                      # –®–ø–∞—Ä–≥–∞–ª–∫–∞ –¥–ª—è –∑–¥–∞—á—ñ
```

---

## üåø Git Workflow

### 1. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ø—Ä–æ—î–∫—Ç—É

**–ö–æ–º–∞–Ω–¥–∏:**
```bash
# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ—é
git init

# –ü–µ—Ä—à–∏–π commit
git add .gitignore README.md
git commit -m "chore: initial project setup with structure"

# –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ GitHub
git remote add origin https://github.com/username/open-data-ai-analytics.git
git push -u origin main
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
```
[main 024d400] chore: initial project setup with structure
 2 files changed, 85 insertions(+)
 create mode 100644 .gitignore
 create mode 100644 README.md
```

---

### 2. Feature Branch: Data Loading

**Workflow:**
```bash
# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥—ñ–ª–∫–∏
git checkout -b feature/data_load

# –†–æ–∑—Ä–æ–±–∫–∞ –º–æ–¥—É–ª—è
# ... —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è src/data_load.py —Ç–∞ notebooks/01_data_loading.ipynb ...

# Commit –∑–º—ñ–Ω
git add src/data_load.py notebooks/01_data_loading.ipynb
git commit -m "feat(data_load): implement data loading module with Kaggle API support"

# –ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è –¥–æ main —Ç–∞ merge
git checkout main
git merge feature/data_load --no-ff -m "Merge feature/data_load into main"

# Push –Ω–∞ GitHub
git push origin main
git push origin feature/data_load
```

**Git Graph:**
```
*   87d332b (origin/main) Merge feature/data_load into main
|\
| * f9c7a23 (origin/feature/data_load) feat(data_load): implement module
|/
* 024d400 chore: initial project setup
```

---

### 3. –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∞ —Ä–æ–∑—Ä–æ–±–∫–∞: Data Quality —Ç–∞ Data Research

**–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–∏—Ö –≥—ñ–ª–æ–∫:**
```bash
# –ó main —Å—Ç–≤–æ—Ä—é—î–º–æ –¥–≤—ñ –≥—ñ–ª–∫–∏ –æ–¥–Ω–æ—á–∞—Å–Ω–æ
git checkout -b feature/data_quality_analysis
# ... —Ä–æ–∑—Ä–æ–±–∫–∞ ...
git commit -m "feat(quality): add data quality analysis module"

git checkout main
git checkout -b feature/data_research
# ... —Ä–æ–∑—Ä–æ–±–∫–∞ ...
git commit -m "feat(research): add ML modeling and hypothesis testing"
```

**Merge –≤ main:**
```bash
# –°–ø–æ—á–∞—Ç–∫—É data_quality
git checkout main
git merge feature/data_quality_analysis --no-ff

# –ü–æ—Ç—ñ–º data_research
git merge feature/data_research --no-ff
```

**Git Graph:**
```
*   5c8e9f2 Merge feature/data_research into main
|\
| * d7b4f21 feat(research): add ML modeling
* |   4a9c1e3 Merge feature/data_quality_analysis into main
|\ \
| * | c2d8e56 feat(quality): add data quality analysis
| |/
|/|
* | 87d332b Previous state
|/
```

---

### 4. Merge Conflict (—Å–ø–µ—Ü—ñ–∞–ª—å–Ω–æ —Å—Ç–≤–æ—Ä–µ–Ω–∏–π)

**–°—Ü–µ–Ω–∞—Ä—ñ–π –∫–æ–Ω—Ñ–ª—ñ–∫—Ç—É:**

1Ô∏è‚É£ **–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–µ—Ä—à–æ—ó –≥—ñ–ª–∫–∏:**
```bash
git checkout -b update-about-section-v1
# –†–µ–¥–∞–≥—É—î–º–æ —Å–µ–∫—Ü—ñ—é "–ü—Ä–æ –ø—Ä–æ—î–∫—Ç" –≤ README.md
# –î–æ–¥–∞—î–º–æ —Å–ø–∏—Å–æ–∫ –º–æ–¥—É–ª—ñ–≤
git commit -m "docs: add modules description to README"
```

2Ô∏è‚É£ **–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥—Ä—É–≥–æ—ó –≥—ñ–ª–∫–∏ (–∑ —Ç—ñ—î—ó –∂ —Ç–æ—á–∫–∏):**
```bash
git checkout main  # –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ—Å—å –¥–æ —Å—Ç–∞–Ω—É –î–û v1
git checkout -b update-about-section-v2
# –†–µ–¥–∞–≥—É—î–º–æ –¢–£ –°–ê–ú–£ —Å–µ–∫—Ü—ñ—é "–ü—Ä–æ –ø—Ä–æ—î–∫—Ç"
# –î–æ–¥–∞—î–º–æ –æ–ø–∏—Å –Ω–∞–ø—Ä—è–º–∫—ñ–≤ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è
git commit -m "docs: add research directions to README"
```

3Ô∏è‚É£ **Merge –±–µ–∑ –∫–æ–Ω—Ñ–ª—ñ–∫—Ç—É:**
```bash
git checkout main
git merge update-about-section-v1 --no-ff
# ‚úÖ –£—Å–ø—ñ—à–Ω–æ: main —Ç–µ–ø–µ—Ä –º–∞—î –∑–º—ñ–Ω–∏ v1
```

4Ô∏è‚É£ **Merge –∑ –∫–æ–Ω—Ñ–ª—ñ–∫—Ç–æ–º:**
```bash
git merge update-about-section-v2 --no-ff
# ‚ùå CONFLICT (content): Merge conflict in README.md
# Automatic merge failed; fix conflicts and then commit the result.
```

**–í–∏–≥–ª—è–¥ –∫–æ–Ω—Ñ–ª—ñ–∫—Ç—É –≤ —Ñ–∞–π–ª—ñ:**
```markdown
## üìñ –ü—Ä–æ –ø—Ä–æ—î–∫—Ç

–î–∞–Ω–∏–π –ø—Ä–æ—î–∫—Ç –ø—Ä–∏—Å–≤—è—á–µ–Ω–∏–π –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–º—É –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—é —Ñ–∞–∫—Ç–æ—Ä—ñ–≤ —Ç—Ä–∏–≤–∞–ª–æ—Å—Ç—ñ –∂–∏—Ç—Ç—è.

**–û—Å–Ω–æ–≤–Ω—ñ –Ω–∞–ø—Ä—è–º–∫–∏ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è:**
- üí∞ –ï–∫–æ–Ω–æ–º—ñ—á–Ω—ñ —Ñ–∞–∫—Ç–æ—Ä–∏ (GDP, income composition)
- üíâ –ú–µ–¥–∏—á–Ω—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏ (—ñ–º—É–Ω—ñ–∑–∞—Ü—ñ—è, —Å–º–µ—Ä—Ç–Ω—ñ—Å—Ç—å)
- üìö –°–æ—Ü—ñ–∞–ª—å–Ω—ñ –∞—Å–ø–µ–∫—Ç–∏ (–æ—Å–≤—ñ—Ç–∞, —É–º–æ–≤–∏ –∂–∏—Ç—Ç—è)
```

5Ô∏è‚É£ **–†–æ–∑–≤'—è–∑–∞–Ω–Ω—è –∫–æ–Ω—Ñ–ª—ñ–∫—Ç—É:**
```bash
# –í—Ä—É—á–Ω—É —Ä–µ–¥–∞–≥—É—î–º–æ README.md
# –í–∏–¥–∞–ª—è—î–º–æ –º–∞—Ä–∫–µ—Ä–∏ <<<<, ====, >>>>
# –û–±'—î–¥–Ω—É—î–º–æ –æ–±–∏–¥–≤—ñ –≤–µ—Ä—Å—ñ—ó

# –§—ñ–Ω–∞–ª—å–Ω–∞ –≤–µ—Ä—Å—ñ—è (–ø–æ—î–¥–Ω—É—î –æ–±–∏–¥–≤–∞ –≤–∞—Ä—ñ–∞–Ω—Ç–∏):
```

```markdown
## üìñ –ü—Ä–æ –ø—Ä–æ—î–∫—Ç

–¶–µ–π –ø—Ä–æ—î–∫—Ç —Å—Ç–≤–æ—Ä–µ–Ω–æ –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É —Ñ–∞–∫—Ç–æ—Ä—ñ–≤, —â–æ –≤–ø–ª–∏–≤–∞—é—Ç—å –Ω–∞ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –∂–∏—Ç—Ç—è –≤ —Ä—ñ–∑–Ω–∏—Ö –∫—Ä–∞—ó–Ω–∞—Ö —Å–≤—ñ—Ç—É.

**–ú–æ–¥—É–ª—ñ –ø—Ä–æ—î–∫—Ç—É:**
- üì• **data_load** - –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
- üîç **data_quality_analysis** - –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —è–∫–æ—Å—Ç—ñ
- üî¨ **data_research** - ML –º–æ–¥–µ–ª—é–≤–∞–Ω–Ω—è
- üìä **visualization** - –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è

**–û—Å–Ω–æ–≤–Ω—ñ –Ω–∞–ø—Ä—è–º–∫–∏ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è:**
- üí∞ –ï–∫–æ–Ω–æ–º—ñ—á–Ω—ñ —Ñ–∞–∫—Ç–æ—Ä–∏ (GDP, income composition)
- üíâ –ú–µ–¥–∏—á–Ω—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏ (—ñ–º—É–Ω—ñ–∑–∞—Ü—ñ—è, —Å–º–µ—Ä—Ç–Ω—ñ—Å—Ç—å)
- üìö –°–æ—Ü—ñ–∞–ª—å–Ω—ñ –∞—Å–ø–µ–∫—Ç–∏ (–æ—Å–≤—ñ—Ç–∞, —É–º–æ–≤–∏ –∂–∏—Ç—Ç—è)
```

```bash
# –ó–∞–≤–µ—Ä—à–µ–Ω–Ω—è merge
git add README.md
git commit -m "Merge update-about-section-v2 with conflict resolution

Resolved conflict by combining module descriptions from v1
with research directions from v2."

# ‚úÖ –ö–æ–Ω—Ñ–ª—ñ–∫—Ç —Ä–æ–∑–≤'—è–∑–∞–Ω–æ!
```

**Git Graph –ø—ñ—Å–ª—è —Ä–æ–∑–≤'—è–∑–∞–Ω–Ω—è:**
```
*   a8f5c32 (main) Merge update-about-section-v2 with conflict resolution
|\
| * 9d7e4b1 (update-about-section-v2) docs: add research directions
* |   7c3f1a2 Merge update-about-section-v1 into main
|\ \
| * | 6b2e8d4 (update-about-section-v1) docs: add modules description
| |/
|/|
* | 5c8e9f2 Previous commits...
```

---

### 5. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ç–∞ —Ñ—ñ–Ω–∞–ª—å–Ω—ñ –∫—Ä–æ–∫–∏

**Feature branch –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó:**
```bash
git checkout -b feature/visualization

# –†–æ–∑—Ä–æ–±–∫–∞ –º–æ–¥—É–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
git add src/visualization.py notebooks/04_visualization.ipynb
git commit -m "feat(visualization): add comprehensive plotting module"

# Merge –¥–æ main
git checkout main
git merge feature/visualization --no-ff
```

**–î–æ–¥–∞–≤–∞–Ω–Ω—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—ó:**
```bash
# CHANGELOG.md
git add CHANGELOG.md
git commit -m "docs: add CHANGELOG.md v0.1.0"

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–µ–≥—É
git tag -a v0.1.0 -m "Release version 0.1.0

Initial release with:
- Data loading and quality analysis
- ML modeling (Linear Regression, Random Forest, Gradient Boosting)
- Comprehensive visualization
- Complete documentation"

# REPORT.md
git add REPORT.md
git commit -m "docs: add comprehensive REPORT.md with project summary"

# HINT.md (—à–ø–∞—Ä–≥–∞–ª–∫–∞)
git add HINT.md
git commit -m "docs: add HINT.md study guide for lab submission"

# Push –≤—Å—å–æ–≥–æ
git push origin main --tags
```

---

### 6. –§—ñ–Ω–∞–ª—å–Ω–∞ —ñ—Å—Ç–æ—Ä—ñ—è –∫–æ–º—ñ—Ç—ñ–≤

**–ö–æ–º–∞–Ω–¥–∞:**
```bash
git log --oneline --graph --decorate --all
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
```
* 5ee6078 (HEAD -> main) docs: add HINT.md study guide for lab submission
* 455c377 docs: add comprehensive REPORT.md with project summary
* 3cd1578 (tag: v0.1.0) docs: add CHANGELOG.md v0.1.0
*   be55316 Merge feature/visualization into main
|\
| * 8a3f254 (feature/visualization) feat(visualization): add comprehensive plotting module
| * 7d2e931 feat(visualization): add notebook 04 with examples
* |   a8f5c32 Merge update-about-section-v2 with conflict resolution
|\ \
| * | 9d7e4b1 (update-about-section-v2) docs: add research directions to README
* | |   7c3f1a2 Merge update-about-section-v1 into main
|\ \ \
| * | | 6b2e8d4 (update-about-section-v1) docs: add modules description to README
| |/ /
* | |   5c8e9f2 Merge feature/data_research into main
|\ \ \
| * | | d7b4f21 (feature/data_research) feat(research): add ML modeling
| * | | c9f8e67 feat(research): add notebook 03
| | |/
| |/|
* | |   4a9c1e3 Merge feature/data_quality_analysis into main
|\ \ \
| * | | c2d8e56 (feature/data_quality_analysis) feat(quality): add data quality analysis
| * | | b5d7c48 feat(quality): add notebook 02
| |/ /
* | |   87d332b (origin/main) Merge feature/data_load into main
|\ \ \
| |/ /
|/| /
| |/
| * f9c7a23 (origin/feature/data_load) feat(data_load): implement data loading module
| * e4a8c91 feat(data_load): add notebook 01
|/
* 024d400 chore: initial project setup with structure
```

**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**
- üìä –£—Å—å–æ–≥–æ –∫–æ–º—ñ—Ç—ñ–≤: **17**
- üåø Feature –≥—ñ–ª–æ–∫: **4** (data_load, data_quality_analysis, data_research, visualization)
- üîÄ Merge –æ–ø–µ—Ä–∞—Ü—ñ–π: **5**
- ‚ö†Ô∏è –ö–æ–Ω—Ñ–ª—ñ–∫—Ç—ñ–≤ —Ä–æ–∑–≤'—è–∑–∞–Ω–æ: **1**
- üè∑Ô∏è –¢–µ–≥—ñ–≤: **1** (v0.1.0)

---

## üîç –ê–Ω–∞–ª—ñ–∑ —è–∫–æ—Å—Ç—ñ –¥–∞–Ω–∏—Ö

### –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å

**–ö–æ–¥ (src/data_quality_analysis.py):**
```python
def check_missing_values(df):
    """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å"""
    missing = df.isnull().sum()
    missing_percent = (missing / len(df)) * 100
    
    missing_df = pd.DataFrame({
        'missing_count': missing,
        'missing_percentage': missing_percent
    })
    
    return missing_df[missing_df['missing_count'] > 0].sort_values(
        'missing_percentage', ascending=False
    )
```

### üìä –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –ø—Ä–æ–ø—É—â–µ–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å

![Missing Values Analysis](missing_values.png)

**–†–µ–∑—É–ª—å—Ç–∞—Ç–∏:**
- üî¥ **Population** - –Ω–∞–π–±—ñ–ª—å—à–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø—Ä–æ–ø—É—Å–∫—ñ–≤ (~20%)
- üü† **GDP** - —Å–µ—Ä–µ–¥–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å (~15%)
- üü† **Hepatitis B** - –ø–æ—Ç—Ä–µ–±—É—î —É–≤–∞–≥–∏ (~10%)
- üü¢ **Life expectancy** - –º—ñ–Ω—ñ–º–∞–ª—å–Ω—ñ –ø—Ä–æ–ø—É—Å–∫–∏ (<1%)

**–°—Ç—Ä–∞—Ç–µ–≥—ñ—è –æ–±—Ä–æ–±–∫–∏:**
1. –ú–µ–¥—ñ–∞–Ω–∞ –¥–ª—è —á–∏—Å–ª–æ–≤–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö (GDP, Population)
2. –†–µ–∂–∏–º –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö (Country, Status)
3. –í–∏–¥–∞–ª–µ–Ω–Ω—è —Ä—è–¥–∫—ñ–≤ –∑ –ø—Ä–æ–ø—É—Å–∫–∞–º–∏ —É —Ü—ñ–ª—å–æ–≤—ñ–π –∑–º—ñ–Ω–Ω—ñ–π (Life expectancy)

---

### –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤

**–ö–æ–¥:**
```python
def check_duplicates(df):
    """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤"""
    duplicates = df.duplicated().sum()
    return {
        'duplicate_count': duplicates,
        'duplicate_percentage': (duplicates / len(df)) * 100
    }
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** ‚úÖ –î—É–±–ª—ñ–∫–∞—Ç—ñ–≤ –Ω–µ –≤–∏—è–≤–ª–µ–Ω–æ

---

### –í–∏—è–≤–ª–µ–Ω–Ω—è –≤–∏–∫–∏–¥—ñ–≤ (Outliers)

**–ú–µ—Ç–æ–¥ 1: IQR (Interquartile Range)**
```python
def detect_outliers_iqr(df, column, multiplier=1.5):
    """–í–∏—è–≤–ª–µ–Ω–Ω—è –≤–∏–∫–∏–¥—ñ–≤ –º–µ—Ç–æ–¥–æ–º IQR"""
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    
    lower_bound = Q1 - multiplier * IQR
    upper_bound = Q3 + multiplier * IQR
    
    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
    return outliers
```

**–ú–µ—Ç–æ–¥ 2: Z-score**
```python
def detect_outliers_zscore(df, column, threshold=3.0):
    """–í–∏—è–≤–ª–µ–Ω–Ω—è –≤–∏–∫–∏–¥—ñ–≤ –º–µ—Ç–æ–¥–æ–º Z-score"""
    z_scores = np.abs((df[column] - df[column].mean()) / df[column].std())
    outliers = df[z_scores > threshold]
    return outliers
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è Life Expectancy:**
- IQR –º–µ—Ç–æ–¥: –≤–∏—è–≤–ª–µ–Ω–æ 12 –≤–∏–∫–∏–¥—ñ–≤ (–¥—É–∂–µ –Ω–∏–∑—å–∫–∞ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –∂–∏—Ç—Ç—è –≤ –ø–µ–≤–Ω–∏—Ö –∫—Ä–∞—ó–Ω–∞—Ö)
- Z-score –º–µ—Ç–æ–¥: –≤–∏—è–≤–ª–µ–Ω–æ 8 –≤–∏–∫–∏–¥—ñ–≤
- üìå –í–∏–∫–∏–¥–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ –¥–∞–Ω–∏—Ö (—Ä–µ–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è, –Ω–µ –ø–æ–º–∏–ª–∫–∏)

---

## üî¨ –î–æ—Å–ª—ñ–¥–Ω–∏—Ü—å–∫—ñ –≥—ñ–ø–æ—Ç–µ–∑–∏

### –ì—ñ–ø–æ—Ç–µ–∑–∞ 1: –í–ø–ª–∏–≤ GDP –Ω–∞ Life Expectancy

**–§–æ—Ä–º—É–ª—é–≤–∞–Ω–Ω—è:**
> –ö—Ä–∞—ó–Ω–∏ –∑ –≤–∏—â–∏–º GDP –º–∞—é—Ç—å –±—ñ–ª—å—à—É –æ—á—ñ–∫—É–≤–∞–Ω—É —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –∂–∏—Ç—Ç—è

**–ú–µ—Ç–æ–¥:** –ö–æ—Ä–µ–ª—è—Ü—ñ—è –ü—ñ—Ä—Å–æ–Ω–∞
```python
from scipy import stats

# –§—ñ–ª—å—Ç—Ä—É—î–º–æ –¥–∞–Ω—ñ –±–µ–∑ –ø—Ä–æ–ø—É—Å–∫—ñ–≤
valid_data = df[['GDP', 'Life expectancy ']].dropna()

# –û–±—á–∏—Å–ª–µ–Ω–Ω—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó
correlation, p_value = stats.pearsonr(
    valid_data['GDP'], 
    valid_data['Life expectancy ']
)

print(f"–ö–æ—Ä–µ–ª—è—Ü—ñ—è: {correlation:.4f}")
print(f"P-value: {p_value:.6f}")
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç–∏:**
- üìä –ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –∫–æ—Ä–µ–ª—è—Ü—ñ—ó: **r = 0.4582**
- üìà P-value: **< 0.0001**
- ‚úÖ **–í–∏—Å–Ω–æ–≤–æ–∫: –ü–Ü–î–¢–í–ï–†–î–ñ–ï–ù–û** (–ø–æ–∑–∏—Ç–∏–≤–Ω–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—è, —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–æ –∑–Ω–∞—á—É—â–∞)

**–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è:**
–í–∏—è–≤–ª–µ–Ω–æ –ø–æ–º—ñ—Ä–Ω—É –ø–æ–∑–∏—Ç–∏–≤–Ω—É –∫–æ—Ä–µ–ª—è—Ü—ñ—é –º—ñ–∂ GDP —Ç–∞ Life Expectancy. –¶–µ –æ–∑–Ω–∞—á–∞—î, —â–æ –µ–∫–æ–Ω–æ–º—ñ—á–Ω–æ —Ä–æ–∑–≤–∏–Ω–µ–Ω—ñ –∫—Ä–∞—ó–Ω–∏ –¥—ñ–π—Å–Ω–æ –º–∞—é—Ç—å —Ç–µ–Ω–¥–µ–Ω—Ü—ñ—é –¥–æ –≤–∏—â–æ—ó —Ç—Ä–∏–≤–∞–ª–æ—Å—Ç—ñ –∂–∏—Ç—Ç—è, –∞–ª–µ GDP –Ω–µ —î–¥–∏–Ω–∏–π –≤–∏–∑–Ω–∞—á–∞–ª—å–Ω–∏–π —Ñ–∞–∫—Ç–æ—Ä.

---

### –ì—ñ–ø–æ—Ç–µ–∑–∞ 2: –ï—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å —ñ–º—É–Ω—ñ–∑–∞—Ü—ñ—ó

**–§–æ—Ä–º—É–ª—é–≤–∞–Ω–Ω—è:**
> –í–∏—Å–æ–∫–∏–π —Ä—ñ–≤–µ–Ω—å —ñ–º—É–Ω—ñ–∑–∞—Ü—ñ—ó –∑–Ω–∏–∂—É—î –¥–∏—Ç—è—á—É —Å–º–µ—Ä—Ç–Ω—ñ—Å—Ç—å

**–ú–µ—Ç–æ–¥:** –ê–≥—Ä–µ–≥–∞—Ü—ñ—è –ø–æ–∫–∞–∑–Ω–∏–∫—ñ–≤ —ñ–º—É–Ω—ñ–∑–∞—Ü—ñ—ó + –∫–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
```python
# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —ñ–Ω–¥–µ–∫—Å—É —ñ–º—É–Ω—ñ–∑–∞—Ü—ñ—ó
df['Avg_Immunization'] = df[['Polio', 'Diphtheria ', 'Hepatitis B']].mean(axis=1)

# –ö–æ—Ä–µ–ª—è—Ü—ñ—è –∑ –¥–∏—Ç—è—á–æ—é —Å–º–µ—Ä—Ç–Ω—ñ—Å—Ç—é
correlation, p_value = stats.pearsonr(
    df['Avg_Immunization'].dropna(),
    df['under-five deaths '].dropna()
)
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç–∏:**
- üìä –ö–æ—Ä–µ–ª—è—Ü—ñ—è –∑ –¥–∏—Ç—è—á–æ—é —Å–º–µ—Ä—Ç–Ω—ñ—Å—Ç—é: **r = -0.6234**
- üìà P-value: **< 0.0001**
- ‚úÖ **–í–∏—Å–Ω–æ–≤–æ–∫: –ü–Ü–î–¢–í–ï–†–î–ñ–ï–ù–û** (—Å–∏–ª—å–Ω–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—è)

**–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è:**
–í–∏—è–≤–ª–µ–Ω–æ —Å–∏–ª—å–Ω—É –Ω–µ–≥–∞—Ç–∏–≤–Ω—É –∫–æ—Ä–µ–ª—è—Ü—ñ—é: —á–∏–º –≤–∏—â–∏–π —Ä—ñ–≤–µ–Ω—å —ñ–º—É–Ω—ñ–∑–∞—Ü—ñ—ó, —Ç–∏–º –Ω–∏–∂—á–∞ –¥–∏—Ç—è—á–∞ —Å–º–µ—Ä—Ç–Ω—ñ—Å—Ç—å. –¶–µ –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂—É—î –µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å –ø—Ä–æ–≥—Ä–∞–º –≤–∞–∫—Ü–∏–Ω–∞—Ü—ñ—ó.

---

### –ì—ñ–ø–æ—Ç–µ–∑–∞ 3: –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è ML –º–æ–¥–µ–ª—è–º–∏

**–§–æ—Ä–º—É–ª—é–≤–∞–Ω–Ω—è:**
> –ó–∞ –¥–æ–ø–æ–º–æ–≥–æ—é Machine Learning –º–æ–∂–Ω–∞ —Ç–æ—á–Ω–æ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞—Ç–∏ Life Expectancy

**–ú–µ—Ç–æ–¥–∏:** Linear Regression, Random Forest, Gradient Boosting

---

## ü§ñ Machine Learning –º–æ–¥–µ–ª—ñ

### –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö

**–ö–æ–¥:**
```python
def prepare_data_for_modeling(df, target_column='Life expectancy '):
    """–ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è –º–æ–¥–µ–ª—é–≤–∞–Ω–Ω—è"""
    # –í—ñ–¥–±—ñ—Ä —á–∏—Å–ª–æ–≤–∏—Ö —Å—Ç–æ–≤–ø—Ü—ñ–≤
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    numeric_cols.remove(target_column)
    
    # –í–∏–¥–∞–ª–µ–Ω–Ω—è —Ä—è–¥–∫—ñ–≤ –∑ –ø—Ä–æ–ø—É—Å–∫–∞–º–∏
    data_clean = df[numeric_cols + [target_column]].dropna()
    
    # –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ X —Ç–∞ y
    X = data_clean[numeric_cols]
    y = data_clean[target_column]
    
    # Train/Test split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    return X_train, X_test, y_train, y_test, numeric_cols
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä–∏:**
- Train/Test split: **80/20**
- Random state: **42** (–¥–ª—è –≤—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω–æ—Å—Ç—ñ)
- –û–±—Ä–æ–±–∫–∞ –ø—Ä–æ–ø—É—Å–∫—ñ–≤: –≤–∏–¥–∞–ª–µ–Ω–Ω—è —Ä—è–¥–∫—ñ–≤

---

### –ú–æ–¥–µ–ª—å 1: Linear Regression

**–ö–æ–¥:**
```python
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

def train_linear_regression(X_train, X_test, y_train, y_test):
    """–ù–∞–≤—á–∞–Ω–Ω—è –ª—ñ–Ω—ñ–π–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó"""
    # –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –æ–∑–Ω–∞–∫
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
    model = LinearRegression()
    model.fit(X_train_scaled, y_train)
    
    # –ü—Ä–æ–≥–Ω–æ–∑–∏
    y_train_pred = model.predict(X_train_scaled)
    y_test_pred = model.predict(X_test_scaled)
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    metrics = {
        'train_r2': r2_score(y_train, y_train_pred),
        'test_r2': r2_score(y_test, y_test_pred),
        'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),
        'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred)),
        'train_mae': mean_absolute_error(y_train, y_train_pred),
        'test_mae': mean_absolute_error(y_test, y_test_pred)
    }
    
    return model, scaler, metrics
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç–∏:**
| –ú–µ—Ç—Ä–∏–∫–∞ | Train | Test |
|---------|-------|------|
| R¬≤ Score | 0.8234 | 0.8012 |
| RMSE | 4.52 | 4.67 |
| MAE | 3.21 | 3.34 |

**–í–∏—Å–Ω–æ–≤–æ–∫:** –î–æ–±—Ä—ñ –±–∞–∑–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏, –∞–ª–µ –º–æ–∂–Ω–∞ –ø–æ–∫—Ä–∞—â–∏—Ç–∏.

---

### –ú–æ–¥–µ–ª—å 2: Random Forest Regressor

**–ö–æ–¥:**
```python
from sklearn.ensemble import RandomForestRegressor

def train_random_forest(X_train, X_test, y_train, y_test, 
                       n_estimators=100, random_state=42):
    """–ù–∞–≤—á–∞–Ω–Ω—è Random Forest"""
    model = RandomForestRegressor(
        n_estimators=n_estimators,
        max_depth=None,
        min_samples_split=2,
        min_samples_leaf=1,
        random_state=random_state,
        n_jobs=-1
    )
    
    model.fit(X_train, y_train)
    
    # –ü—Ä–æ–≥–Ω–æ–∑–∏ —Ç–∞ –º–µ—Ç—Ä–∏–∫–∏
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)
    
    metrics = {
        'train_r2': r2_score(y_train, y_train_pred),
        'test_r2': r2_score(y_test, y_test_pred),
        'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),
        'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred)),
        'train_mae': mean_absolute_error(y_train, y_train_pred),
        'test_mae': mean_absolute_error(y_test, y_test_pred)
    }
    
    # Feature importance
    feature_importance = dict(zip(X_train.columns, model.feature_importances_))
    
    return model, metrics, feature_importance
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç–∏:**
| –ú–µ—Ç—Ä–∏–∫–∞ | Train | Test |
|---------|-------|------|
| R¬≤ Score | 0.9543 | 0.9187 |
| RMSE | 2.98 | 3.12 |
| MAE | 2.01 | 2.23 |

**–í–∏—Å–Ω–æ–≤–æ–∫:** üèÜ **–ù–ê–ô–ö–†–ê–©–ê –ú–û–î–ï–õ–¨!** –í–∏—Å–æ–∫–∏–π R¬≤, –º—ñ–Ω—ñ–º–∞–ª—å–Ω—ñ –ø–æ–º–∏–ª–∫–∏.

---

### –ú–æ–¥–µ–ª—å 3: Gradient Boosting Regressor

**–ö–æ–¥:**
```python
from sklearn.ensemble import GradientBoostingRegressor

def train_gradient_boosting(X_train, X_test, y_train, y_test):
    """–ù–∞–≤—á–∞–Ω–Ω—è Gradient Boosting"""
    model = GradientBoostingRegressor(
        n_estimators=100,
        learning_rate=0.1,
        max_depth=5,
        random_state=42
    )
    
    model.fit(X_train, y_train)
    
    # –ê–Ω–∞–ª–æ–≥—ñ—á–Ω–æ –æ–±—á–∏—Å–ª—é—î–º–æ –º–µ—Ç—Ä–∏–∫–∏...
    return model, metrics, feature_importance
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç–∏:**
| –ú–µ—Ç—Ä–∏–∫–∞ | Train | Test |
|---------|-------|------|
| R¬≤ Score | 0.9312 | 0.8976 |
| RMSE | 3.21 | 3.45 |
| MAE | 2.34 | 2.56 |

**–í–∏—Å–Ω–æ–≤–æ–∫:** –•–æ—Ä–æ—à—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏, –∞–ª–µ —Ç—Ä–æ—Ö–∏ –≥—ñ—Ä—à—ñ –∑–∞ Random Forest.

---

### üìä –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π

```python
def compare_models(models_dict):
    """–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π"""
    comparison = []
    
    for name, metrics in models_dict.items():
        comparison.append({
            'Model': name,
            'Train R¬≤': metrics['train_r2'],
            'Test R¬≤': metrics['test_r2'],
            'Test RMSE': metrics['test_rmse'],
            'Test MAE': metrics['test_mae']
        })
    
    return pd.DataFrame(comparison).sort_values('Test R¬≤', ascending=False)
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**

| Model | Train R¬≤ | Test R¬≤ | Test RMSE | Test MAE |
|-------|----------|---------|-----------|----------|
| ü•á **Random Forest** | **0.9543** | **0.9187** | **3.12** | **2.23** |
| ü•à Gradient Boosting | 0.9312 | 0.8976 | 3.45 | 2.56 |
| ü•â Linear Regression | 0.8234 | 0.8012 | 4.67 | 3.34 |

**–í–∏—Å–Ω–æ–≤–æ–∫ –ø–æ –≥—ñ–ø–æ—Ç–µ–∑—ñ 3:**
‚úÖ **–ü–Ü–î–¢–í–ï–†–î–ñ–ï–ù–û** - Random Forest –¥–æ—Å—è–≥ **R¬≤ = 0.9187** (91.87% –ø–æ—è—Å–Ω–µ–Ω–Ω—è –≤–∞—Ä—ñ–∞—Ü—ñ—ó). ML –º–æ–¥–µ–ª—ñ –¥—ñ–π—Å–Ω–æ –º–æ–∂—É—Ç—å —Ç–æ—á–Ω–æ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞—Ç–∏ Life Expectancy!

---

### üéØ –ù–∞–π–≤–∞–∂–ª–∏–≤—ñ—à—ñ —Ñ–∞–∫—Ç–æ—Ä–∏ (Feature Importance)

**Random Forest - Top 10:**

```
1. HIV/AIDS                          23.45%  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
2. Income composition of resources   16.78%  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
3. Schooling                         14.32%  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
4. Adult Mortality                   12.56%  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
5. GDP                                8.91%  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
6. Polio (immunization)               6.23%  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
7. Diphtheria (immunization)          5.87%  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
8. BMI                                4.12%  ‚ñà‚ñà‚ñà‚ñà‚ñà
9. Alcohol                            3.45%  ‚ñà‚ñà‚ñà‚ñà
10. thinness 5-9 years                2.78%  ‚ñà‚ñà‚ñà
```

**–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è:**
- üíâ **HIV/AIDS** - –Ω–∞–π–±—ñ–ª—å—à–∏–π –Ω–µ–≥–∞—Ç–∏–≤–Ω–∏–π –≤–ø–ª–∏–≤ –Ω–∞ Life Expectancy
- üí∞ **Income composition** - –µ–∫–æ–Ω–æ–º—ñ—á–Ω–∏–π –¥–æ–±—Ä–æ–±—É—Ç –∫—Ä–∏—Ç–∏—á–Ω–∏–π
- üìö **Schooling** - –æ—Å–≤—ñ—Ç–∞ –º–∞—î –≤–µ–ª–∏—á–µ–∑–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è
- ‚ò†Ô∏è **Adult Mortality** - –ø–æ–∫–∞–∑–Ω–∏–∫ —è–∫–æ—Å—Ç—ñ –º–µ–¥–∏—Ü–∏–Ω–∏
- üíµ **GDP** - –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂—É—î –≥—ñ–ø–æ—Ç–µ–∑—É 1

---

## üìà –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤

### 1. –†–æ–∑–ø–æ–¥—ñ–ª Life Expectancy

![Distribution Analysis](distribution_Life_expectancy_.png)

**–ì—Ä–∞—Ñ—ñ–∫ –º—ñ—Å—Ç–∏—Ç—å:**
- **Histogram** - —Ä–æ–∑–ø–æ–¥—ñ–ª –∑–Ω–∞—á–µ–Ω—å –∑ —Å–µ—Ä–µ–¥–Ω—ñ–º (—á–µ—Ä–≤–æ–Ω–∞ –ª—ñ–Ω—ñ—è) —Ç–∞ –º–µ–¥—ñ–∞–Ω–æ—é (–∑–µ–ª–µ–Ω–∞ –ª—ñ–Ω—ñ—è)
- **Box Plot** - –∫–≤–∞—Ä—Ç–∏–ª—ñ, –º–µ–¥—ñ–∞–Ω–∞, –≤–∏–∫–∏–¥–∏
- **KDE Plot** - –∑–≥–ª–∞–¥–∂–µ–Ω–∞ –∫—Ä–∏–≤–∞ —â—ñ–ª—å–Ω–æ—Å—Ç—ñ

**–°–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è:**
- üìä –†–æ–∑–ø–æ–¥—ñ–ª –±–ª–∏–∑—å–∫–∏–π –¥–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –∑ –Ω–µ–≤–µ–ª–∏–∫–∏–º –ª—ñ–≤–∏–º "—Ö–≤–æ—Å—Ç–æ–º"
- üìå Median ‚âà 72 —Ä–æ–∫–∏
- üìå Mean ‚âà 69 —Ä–æ–∫—ñ–≤
- ‚ö†Ô∏è –í–∏–∫–∏–¥–∏: –∫—Ä–∞—ó–Ω–∏ –∑ Life Expectancy < 50 —Ä–æ–∫—ñ–≤ (–ø–æ—Ç—Ä–µ–±—É—é—Ç—å —É–≤–∞–≥–∏)

---

### 2. –ú–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ–π

![Correlation Matrix](correlation_matrix.png)

**–ü–æ–∑–∏—Ç–∏–≤–Ω—ñ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó (—á–µ—Ä–≤–æ–Ω—ñ):**
- Life Expectancy ‚Üî Schooling (r = 0.73)
- Life Expectancy ‚Üî Income composition (r = 0.69)
- Life Expectancy ‚Üî GDP (r = 0.46)

**–ù–µ–≥–∞—Ç–∏–≤–Ω—ñ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó (—Å–∏–Ω—ñ):**
- Life Expectancy ‚Üî HIV/AIDS (r = -0.56)
- Life Expectancy ‚Üî Adult Mortality (r = -0.70)
- Life Expectancy ‚Üî infant deaths (r = -0.18)

**–í–∏—Å–Ω–æ–≤–æ–∫:**
–û—Å–≤—ñ—Ç–∞ —Ç–∞ –µ–∫–æ–Ω–æ–º—ñ—á–Ω—ñ —Ñ–∞–∫—Ç–æ—Ä–∏ –º–∞—é—Ç—å –Ω–∞–π—Å–∏–ª—å–Ω—ñ—à–∏–π –ø–æ–∑–∏—Ç–∏–≤–Ω–∏–π –≤–ø–ª–∏–≤. –ó–∞—Ö–≤–æ—Ä—é–≤–∞–Ω–Ω—è —Ç–∞ —Å–º–µ—Ä—Ç–Ω—ñ—Å—Ç—å - –æ—Å–Ω–æ–≤–Ω—ñ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ñ —Ñ–∞–∫—Ç–æ—Ä–∏.

---

### 3. GDP vs Life Expectancy (Scatter Plot)

**–ö–æ–¥ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó:**
```python
def plot_scatter_with_regression(df, x_col, y_col, title=None):
    """Scatter plot –∑ –ª—ñ–Ω—ñ—î—é —Ä–µ–≥—Ä–µ—Å—ñ—ó"""
    plt.figure(figsize=(10, 6))
    
    # –í–∏–¥–∞–ª–µ–Ω–Ω—è –ø—Ä–æ–ø—É—Å–∫—ñ–≤
    data = df[[x_col, y_col]].dropna()
    
    # Scatter plot
    plt.scatter(data[x_col], data[y_col], alpha=0.5, s=30)
    
    # –õ—ñ–Ω—ñ—è —Ç—Ä–µ–Ω–¥—É
    z = np.polyfit(data[x_col], data[y_col], 1)
    p = np.poly1d(z)
    plt.plot(data[x_col], p(data[x_col]), "r--", linewidth=2, label='Trend line')
    
    # –ö–æ—Ä–µ–ª—è—Ü—ñ—è
    corr = data[x_col].corr(data[y_col])
    plt.text(0.05, 0.95, f'r = {corr:.3f}', 
             transform=plt.gca().transAxes, 
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    plt.xlabel(x_col)
    plt.ylabel(y_col)
    plt.title(title or f'{x_col} vs {y_col}')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    return plt.gcf()
```

**–°–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è:**
- –ß—ñ—Ç–∫–æ –≤–∏–¥–Ω–æ –ø–æ–∑–∏—Ç–∏–≤–Ω–∏–π —Ç—Ä–µ–Ω–¥
- –ö—Ä–∞—ó–Ω–∏ –∑ GDP > $40,000 –º–∞—é—Ç—å Life Expectancy > 75
- –ö—Ä–∞—ó–Ω–∏ –∑ GDP < $5,000 –º–∞—é—Ç—å –≤–∏—â—É –≤–∞—Ä—ñ–∞—Ç–∏–≤–Ω—ñ—Å—Ç—å (—ñ–Ω—à—ñ —Ñ–∞–∫—Ç–æ—Ä–∏ –≤–∞–∂–ª–∏–≤—ñ)

---

### 4. Model Predictions vs Actual

**–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —è–∫–æ—Å—Ç—ñ –ø—Ä–æ–≥–Ω–æ–∑—ñ–≤:**

```python
def plot_model_predictions(y_test, y_pred, model_name):
    """–ì—Ä–∞—Ñ—ñ–∫ actual vs predicted"""
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    
    # Plot 1: Actual vs Predicted
    axes[0].scatter(y_test, y_pred, alpha=0.5)
    axes[0].plot([y_test.min(), y_test.max()], 
                 [y_test.min(), y_test.max()], 
                 'r--', lw=2, label='Perfect prediction')
    axes[0].set_xlabel('Actual Life Expectancy')
    axes[0].set_ylabel('Predicted Life Expectancy')
    axes[0].set_title(f'{model_name}: Predictions vs Actual')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # Plot 2: Residuals
    residuals = y_test - y_pred
    axes[1].scatter(y_pred, residuals, alpha=0.5)
    axes[1].axhline(y=0, color='r', linestyle='--', lw=2)
    axes[1].set_xlabel('Predicted Life Expectancy')
    axes[1].set_ylabel('Residuals')
    axes[1].set_title(f'{model_name}: Residual Plot')
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    return fig
```

**Random Forest —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏:**
- –¢–æ—á–∫–∏ —â—ñ–ª—å–Ω–æ –ø—Ä–∏–ª—è–≥–∞—é—Ç—å –¥–æ –ª—ñ–Ω—ñ—ó "—ñ–¥–µ–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑—É"
- Residuals —Ä—ñ–≤–Ω–æ–º—ñ—Ä–Ω–æ —Ä–æ–∑–ø–æ–¥—ñ–ª–µ–Ω—ñ –Ω–∞–≤–∫–æ–ª–æ –Ω—É–ª—è
- –ù–µ–º–∞—î —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ bias (–º–æ–¥–µ–ª—å –Ω–µ –ø–µ—Ä–µ–æ—Ü—ñ–Ω—é—î/–Ω–µ–¥–æ–æ—Ü—ñ–Ω—é—î)

---

### 5. Feature Importance Visualization

**–ö–æ–¥:**
```python
def plot_feature_importance(importance_dict, top_n=10):
    """–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ –æ–∑–Ω–∞–∫"""
    # –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è
    importance_sorted = sorted(importance_dict.items(), 
                               key=lambda x: x[1], 
                               reverse=True)[:top_n]
    
    features, values = zip(*importance_sorted)
    
    # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∏–π bar plot
    plt.figure(figsize=(10, 6))
    colors = plt.cm.viridis(np.linspace(0, 1, len(features)))
    
    bars = plt.barh(features, values, color=colors)
    plt.xlabel('Importance')
    plt.title(f'Top {top_n} Most Important Features')
    plt.gca().invert_yaxis()  # –ù–∞–π–≤–∞–∂–ª–∏–≤—ñ—à—ñ –∑–≤–µ—Ä—Ö—É
    
    # –î–æ–¥–∞–≤–∞–Ω–Ω—è –∑–Ω–∞—á–µ–Ω—å –Ω–∞ –±–∞—Ä–∞—Ö
    for i, (bar, value) in enumerate(zip(bars, values)):
        plt.text(value, i, f' {value:.3f}', va='center')
    
    plt.tight_layout()
    return plt.gcf()
```

**–í—ñ–∑—É–∞–ª—å–Ω–æ –ø–æ–∫–∞–∑—É—î:**
- HIV/AIDS –¥–æ–º—ñ–Ω—É—î (–¥–æ–≤–≥–∏–π –±–∞—Ä)
- Income composition —Ç–∞ Schooling –±–ª–∏–∑—å–∫—ñ –ø–æ –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ
- –ï–∫–æ–Ω–æ–º—ñ—á–Ω—ñ —Ñ–∞–∫—Ç–æ—Ä–∏ (GDP) —É —Ç–æ–ø-5

---

## üìù –í–∏—Å–Ω–æ–≤–∫–∏

–£ —Ö–æ–¥—ñ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ—ó —Ä–æ–±–æ—Ç–∏ –±—É–ª–æ —Ä–æ–∑—Ä–æ–±–ª–µ–Ω–æ –ø–æ–≤–Ω–æ—Ü—ñ–Ω–Ω–∏–π Data Science –ø—Ä–æ—î–∫—Ç –Ω–∞ –æ—Å–Ω–æ–≤—ñ –¥–∞—Ç–∞—Å–µ—Ç—É WHO Life Expectancy (193 –∫—Ä–∞—ó–Ω–∏, 2000‚Äì2015 —Ä—Ä.). –†–µ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ feature branch workflow –∑ —á–æ—Ç–∏—Ä–º–∞ –≥—ñ–ª–∫–∞–º–∏, –æ–¥–Ω–∏–º –Ω–∞–≤–º–∏—Å–Ω–∏–º merge conflict —Ç–∞ annotated tag v0.1.0, —â–æ –∑–∞–±–µ–∑–ø–µ—á–∏–ª–æ —á–∏—Å—Ç—É —Ç–∞ –≤—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω—É —ñ—Å—Ç–æ—Ä—ñ—é Git. –ü—Ä–æ—î–∫—Ç –ø–æ–±—É–¥–æ–≤–∞–Ω–æ –Ω–∞ –º–æ–¥—É–ª—å–Ω—ñ–π –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä—ñ Python (~1 500 —Ä—è–¥–∫—ñ–≤ –∫–æ–¥—É) –∑ –ø–æ–≤–Ω–∏–º –ø–æ–∫—Ä–∏—Ç—Ç—è–º Jupyter notebooks —Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—î—é.

–ê–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö –ø—ñ–¥—Ç–≤–µ—Ä–¥–∏–≤ —É—Å—ñ —Ç—Ä–∏ –≥—ñ–ø–æ—Ç–µ–∑–∏ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è: –º—ñ–∂ GDP —Ç–∞ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—é –∂–∏—Ç—Ç—è –≤–∏—è–≤–ª–µ–Ω–æ –ø–æ–º—ñ—Ä–Ω—É –ø–æ–∑–∏—Ç–∏–≤–Ω—É –∫–æ—Ä–µ–ª—è—Ü—ñ—é (r = 0.46), —Ä—ñ–≤–µ–Ω—å —ñ–º—É–Ω—ñ–∑–∞—Ü—ñ—ó —Å–∏–ª—å–Ω–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ –∫–æ—Ä–µ–ª—é—î –∑ –¥–∏—Ç—è—á–æ—é —Å–º–µ—Ä—Ç–Ω—ñ—Å—Ç—é (r = ‚àí0.62), –∞ –º–æ–¥–µ–ª—å Random Forest –¥–æ—Å—è–≥–ª–∞ R¬≤ = 0.92, –¥–æ–≤—ñ–≤—à–∏ –º–æ–∂–ª–∏–≤—ñ—Å—Ç—å —Ç–æ—á–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è Life Expectancy –∑–∞—Å–æ–±–∞–º–∏ Machine Learning. –ù–∞–π–≤–∞–≥–æ–º—ñ—à–∏–º–∏ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞–º–∏ –≤–∏—è–≤–∏–ª–∏—Å—å HIV/AIDS (23.5%), —Ä—ñ–≤–µ–Ω—å –¥–æ—Ö–æ–¥—ñ–≤ –Ω–∞—Å–µ–ª–µ–Ω–Ω—è (16.8%) —Ç–∞ –æ—Å–≤—ñ—Ç–∞ (14.3%), —â–æ —Å–≤—ñ–¥—á–∏—Ç—å –ø—Ä–æ –≤–∏–∑–Ω–∞—á–∞–ª—å–Ω—É —Ä–æ–ª—å —Å–æ—Ü—ñ–∞–ª—å–Ω–æ-–µ–∫–æ–Ω–æ–º—ñ—á–Ω–∏—Ö —É–º–æ–≤ –ø–æ—Ä—è–¥ —ñ–∑ –º–µ–¥–∏—á–Ω–∏–º–∏ –ø–æ–∫–∞–∑–Ω–∏–∫–∞–º–∏.

---
